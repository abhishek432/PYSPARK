{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishek432/PYSPARK/blob/main/spark1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW57xzl7C3IE",
        "outputId": "1c8372f5-a3af-403a-a75f-7dd125b5431b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 39 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 62.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=9d8f98fa5fd08a60392694a1020f2f922d53d660d1369dff9750883047e14361\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0G9KhqaDufc"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark =SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQLsnZpIEFCD",
        "outputId": "36643637-ec2b-4aff-e183-68b4805c4955",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#dataframe Creation by row library ---\n",
        "from datetime import datetime,date\n",
        "import pandas as pd\n",
        "from pyspark.sql import Row\n",
        "df=spark.createDataFrame([ \n",
        "    Row(apple=1,banana=2.,c='hello',d=date(2021,2,4),e=datetime(2021,2,12,1)),\n",
        "    Row(apple=2,banana=3.,c='hello1',d=date(2021,1,4),e=datetime(2021,2,12,0)),\n",
        "    Row(apple=3,banana=4.,c='hello2',d=date(2021,2,5),e=datetime(2021,2,11,1))\n",
        "    ])\n",
        "df\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[apple: bigint, banana: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yJqvI0uJTwM",
        "outputId": "86bb723e-3d3d-447f-c42a-5d66e345dda4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#dataframe creation by pandas----\n",
        "pandas_df=pd.DataFrame({\n",
        "    'apple':[1,2,3],\n",
        "    'banana':[2.,3.,3.],\n",
        "    'c':['hello','hello1','hello2'],\n",
        "    'd':[date(2021,2,4),date(2021,2,4),date(2021,2,4)],\n",
        "    'e':[datetime(2021,2,12,1),datetime(2021,2,12,1),datetime(2021,2,12,1)]\n",
        "    })\n",
        "df=spark.createDataFrame(pandas_df)\n",
        "df\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[apple: bigint, banana: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNdQPLMVKAt6",
        "outputId": "7840a9b1-8d91-42dd-eedc-f7c9d93162a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#creating dataframe with rdd or parallize method---\n",
        "rdd=spark.sparkContext.parallelize([\n",
        "  (1,2.,'hello',date(2021,2,4),datetime(2021,2,12,1)),\n",
        "  (2,3.,'hello',date(2021,2,4),datetime(2021,2,12,1)),\n",
        "  (3,3.,'hello',date(2021,2,4),datetime(2021,2,12,1))    \n",
        "])\n",
        "df=spark.createDataFrame(rdd,schema=['apple','banana','c','d','e'])\n",
        "df\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[apple: bigint, banana: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}